# ğŸ§  LaminaAI â€“ Your Local AI Companion

**LaminaAI** is a developer-friendly framework for building local, conversational AI assistants and companions with **long-term memory**, **context awareness**, and a **customizable personality**.

> Ships with **Lamina** â€“ a warm and playful AI persona â€“ as the default character.

---

## âœ¨ Features

* ğŸ§  **Long-Term Memory** using local ChromaDB (no cloud)
* ğŸ—ï¸ **Message Summarization** and semantic embedding
* ğŸ” **Context Recall** via vector search (RAG-style)
* ğŸ’¬ **Short-Term Memory Queue** (recent chat context)
* âš™ï¸ Built with **Node.js**, **TypeScript**, **FastAPI, ChromaDB (Python)**, and **Ollama LLM**
* ğŸ”„ Easy to switch models via [Ollama](https://ollama.com/) (e.g. gemma3:1b, Hermes, Mistral, etc.)

---

## ğŸš€ Getting Started

### ğŸ³ Requirements

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/) (v2+)

---

### ğŸ“¦ Installation & Setup (Using Docker)

```bash
# Clone the project
git clone https://github.com/rahul-lamkhade/LaminaAI.git
cd LaminaAI

# Build all services
docker-compose build

# Start all services
docker-compose up -d

# Run cli base chat
docker-compose run --rm --service-ports cli-ui

```

---

### ğŸ’  How It Works

* Recent messages are kept in a short-term memory queue (up to 10).
* Older chats are summarized and stored in **ChromaDB** with metadata.
* On each new message:
  * Fetch recent summaries + active short-term queue
  * Perform semantic search if trigger words match (e.g., *"remember"*)
* Final prompt is sent to the LLM (via Ollama) for response generation.
* type 'exit' and enter which will exit the chat. 
---

### ğŸ”Œ API Endpoints (Python Memory Server)

| Endpoint             | Purpose                         |
| -------------------- | ------------------------------- |
| `POST /memory/add`   | Store a summarized memory       |
| `GET /memory/recent` | Get last N memory chunks        |
| `POST /query`        | Semantic memory search (vector) |

---

### ğŸ§  Character: Lamina

Lamina is a warm, emotionally intelligent AI companion. You can customize her personality, tone, and prompt behavior in:

```ts
services/orchestrator/src/agents/lamina.ts
```

---

### ğŸ§± Use Cases

* Personal AI assistant (local & private)
* Mental health journaling support
* Story-based NPCs or game characters
* Offline companions for low-resource environments

---

### ğŸŒ± Contributing

This project is modular and designed to be extended or embedded in other tools. Fork it, remix it, or send a PR.

---

### License

MIT â€” open-source and free to use for personal or commercial projects.

---

### ğŸ“² Coming Soon

* ğŸ§˜ Emotional state tracking
* ğŸ“± Mobile UI (Ionic + Angular)
* ğŸ§ Voice integration (TTS/STT)
* ğŸŒ Web-based UI